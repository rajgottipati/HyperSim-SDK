{"extracted_information": "The web content provides detailed strategies for managing failures in distributed systems, focusing on timeouts, retries, backoff, and jitter, with specific mentions of their application in SDKs.", "specifications": {"timeout_selection_metric": "p99.9 latency percentile of downstream service (within AWS Region)", "timeout_value_example": "20 milliseconds (initial low setting)", "retry_load_amplification_factor_example": "243x (with 3 retries at 5 layers)", "sdk_throttling_implementation_year": 2016}, "pricing": {}, "features": [{"name": "Retry Strategies", "description": "Allow clients to survive partial or transient failures by re-sending requests. Not always safe due to increased load or side effects. Best practice for APIs with side effects is to be idempotent. In multi-layered systems, best practice is to retry at a single point in the stack for low-cost control-plane and data-plane operations. The AWS SDK includes built-in throttling behavior (token bucket) to limit retries and manage load. Distinguishes between HTTP client errors (not to retry) and server errors (may retry), though eventual consistency blurs this line. Requires judgment to balance availability with load amplification. Retries are 'selfish' and demand more resources from the service. Amazon's approach is to retry only when dependency is healthy and stop when retries don't improve availability."}, {"name": "Exponential Backoff Patterns", "description": "Increases the time between subsequent retries to manage load on the backend. The most common pattern is exponential backoff. To prevent excessively long waits, implementations typically use 'capped exponential backoff' by setting a maximum value. However, this can lead to all clients retrying at the same capped rate. The solution is to limit the total number of retries, allowing the client to fail faster."}, {"name": "Connection Management Strategies", "description": "Clients set timeouts to prevent resource exhaustion from long-running requests. This includes both connection timeouts and request timeouts. Choosing the right timeout is critical; too high wastes resources, too low increases traffic and latency from premature retries. Best practice in Amazon is to set timeouts on any remote call, including those across processes on the same machine. Timeout values are typically chosen based on the p99.9 latency percentile of the downstream service. Considerations include network latency for internet-facing clients and padding for services with tight latency bounds. Caution advised for low-level socket options like Linux's SO_RCVTIMEO. Prefer built-in timeouts in well-tested clients. Issues with connection establishment time (e.g., TLS handshakes) are noted; resolved by pre-establishing connections before receiving traffic."}, {"name": "Jitter Implementation", "description": "Adds a random amount of time to backoff delays to spread out retries and prevent correlation (all failed calls retrying simultaneously). This helps mitigate issues caused by overload or contention. Jitter is also applied to other timers, periodic jobs, and delayed work to spread out workload spikes, aiding downstream service scalability. For scheduled work, a consistent method of generating jitter per host is preferred over pure randomness to facilitate troubleshooting by making patterns repeatable. Applying jitter to periodic client workloads (like those on Amazon EBS and AWS Lambda) can reduce server capacity needs. Can be added to customer-triggered tasks if it doesn't impact user experience."}], "statistics": {}, "temporal_info": {"aws_sdk_throttling_feature_release": "2016"}, "geographical_data": {"timeout_selection_scope": "within an AWS Region", "network_latency_consideration": "clients spanning the globe"}, "references": [{"title": "Exponential Backoff and Jitter", "url": "https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/"}]}